id,created_at,published_at,name,body,author_url,author_id,author_login,assets_url,url,target_commitish,tarball_url,html_url,zipball_url,tag_name,draft,prerelease
6971828,2017-07-07T23:21:49Z,2017-07-08T00:33:22Z,Release 1.6.8,"* Fix ReplicaPartitioner Endpoint Call (SPARKC-485)
* MultipleRetryPolicy should retry with null (SPARKC-494)",https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6971828/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6971828,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.8,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.8,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.8,v1.6.8,False,False
6971826,2017-07-07T23:49:19Z,2017-07-08T00:32:48Z,Release 2.0.3,All updates from 1.6.8,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6971826/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6971826,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.3,v2.0.3,False,False
6688827,2017-06-12T21:41:12Z,2017-06-12T23:51:09Z,Release 1.6.7,"Includes:
* Protect against overflows in Size Estimates (SPARKC-492)
* Confirm truncation with datasource writes (SPARKC-472)",https://api.github.com/users/bcantoni,58372,bcantoni,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6688827/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6688827,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.7,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.7,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.7,v1.6.7,False,False
6520711,2017-04-04T20:31:56Z,2017-05-26T22:24:54Z,Release 1.6.6,"Includes:
* Allow Writes to Static Columns and Partition Keys (SPARKC-470)
* SessionProxy Should Proxy all Runtime Interfaces (SPARKC-476)
* Always Use Codec Cache When Reading from Driver Rows (SPARKC-473)",https://api.github.com/users/bcantoni,58372,bcantoni,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6520711/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6520711,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.6,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.6,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.6,v1.6.6,False,False
6520706,2017-05-17T23:24:31Z,2017-05-26T22:24:39Z,Release 2.0.2,"Includes:
  * Protect against Size Estimate Overflows (SPARKC-492)
  * Add java.time classes support to converters and sparkSQL (SPARKC-491)
  * Allow Writes to Static Columns and Partition Keys (SPARKC-470)",https://api.github.com/users/bcantoni,58372,bcantoni,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6520706/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/6520706,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.2,v2.0.2,False,False
5930140,2017-03-06T21:01:57Z,2017-03-30T23:38:55Z,Release 2.0.0,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5930140/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5930140,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.0,v2.0.0,False,False
5930137,2017-03-30T16:16:49Z,2017-03-30T23:38:36Z,Release 2.0.1,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5930137/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5930137,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.1,v2.0.1,False,False
5473423,2017-02-15T22:18:53Z,2017-02-16T04:49:01Z,Release 1.6.5,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5473423/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5473423,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.5,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.5,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.5,v1.6.5,False,False
5156975,2017-01-13T21:08:42Z,2017-01-13T21:51:19Z,Release 1.6.4,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5156975/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5156975,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.4,v1.6.4,False,False
5154473,2017-01-12T21:38:49Z,2017-01-13T17:18:31Z,Release 1.4.5,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5154473/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5154473,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.5,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.5,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.5,v1.4.5,False,False
5154457,2017-01-12T22:39:38Z,2017-01-13T17:17:53Z,Release 1.5.2,,https://api.github.com/users/RussellSpitzer,413025,RussellSpitzer,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5154457/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/5154457,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.2,v1.5.2,False,False
4696607,2016-11-18T09:37:22Z,2016-11-18T10:20:49Z,Release 1.6.3,"1.6.3
- Added SSL client authentication (SPARKC-359)
- Correct order of ""Limit"" and ""orderBy"" clauses in JWCT (SPARKC-433)
- Improved error messages on CreateCassandraTable from DataFrame (SPARKC-428)
- Improved backwards compatibility with older Cassandra versions
  (SPARKC-387, SPARKC-402)
- Fix partitioner on Integer.MIN_VALUE (SPARKC-419)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4696607/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4696607,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.3,v1.6.3,False,False
4018000,2016-08-31T12:18:16Z,2016-08-31T12:41:50Z,Preview release 2.0.0 M3,"This release is to fix shading in the artifacts released to Maven
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4018000/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4018000,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.0-M3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.0-M3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.0-M3,v2.0.0-M3,False,True
4017764,2016-08-31T12:05:27Z,2016-08-31T12:15:24Z,Release 1.6.2,"This release is to fix shading of the artifacts released to Maven. 
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4017764/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/4017764,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.2,v1.6.2,False,False
3976353,2016-08-25T19:15:04Z,2016-08-25T20:14:43Z,Preview release 2.0.0 M2,"This release includes all patches from 1.6.1:

1.6.1
- Disallow TimeUUID Predicate Pushdown (SPARKC-405)
- Avoid overflow on SplitSizeInMB param (SPARKC-413)
- Fix conversion of LocalDate to Joda LocalDate (SPARKC-391)
- Shade Guava to avoid conflict with outdated Guava in Spark (SPARKC-355)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3976353/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3976353,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.0-M2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.0-M2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.0-M2,v2.0.0-M2,False,True
3976343,2016-08-25T17:50:56Z,2016-08-25T20:13:39Z,Release 1.6.1,"1.6.1
- Disallow TimeUUID Predicate Pushdown (SPARKC-405)
- Avoid overflow on SplitSizeInMB param (SPARKC-413)
- Fix conversion of LocalDate to Joda LocalDate (SPARKC-391)
- Shade Guava to avoid conflict with outdated Guava in Spark (SPARKC-355)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3976343/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3976343,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.1,v1.6.1,False,False
3839439,2016-08-08T18:25:43Z,2016-08-08T19:06:33Z,Release 2.0.0 M1 preview,"2.0.0 M1
- Added support for left outer joins with C\* table (SPARKC-181)
- Removed CassandraSqlContext and underscore based options (SPARKC-399)
- Upgrade to Spark 2.0.0 (SPARKC-396)
  - Removed Twitter demo because there is no spark-streaming-twitter package available anymore
  - Removed Akka Actor demo becaues there is no support for such streams anymore
  - Bring back Kafka project and make it compile
  - Update several classes to use our Logging instead of Spark Logging because Spark Logging became private
  - Update few components and tests to make them work with Spark 2.0.0
  - Fix Spark SQL - temporarily
  - Update plugins and Scala version
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3839439/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3839439,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v2.0.0-M1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v2.0.0-M1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v2.0.0-M1,v2.0.0-M1,False,True
3717121,2016-07-22T09:01:26Z,2016-07-22T09:36:13Z,Release 1.2.6,"1.2.6
- Fixed Default ReadConf for JoinWithCassandra Table (SPARKC-294)
- Added refresh cassandra schema cache to CassandraSQLContext (SPARKC-234)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3717121/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3717121,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.6,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.6,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.6,v1.2.6,False,False
3407507,2016-06-09T09:50:05Z,2016-06-09T10:17:53Z,Release 1.5.1,"This release is only for including patches from version 1.4.4.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3407507/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3407507,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.1,v1.5.1,False,False
3407205,2016-06-09T09:21:55Z,2016-06-09T09:31:56Z,Release 1.6.0,"1.6.0
- SparkSql write supports TTL per row (SPARKC-345)
- Make Repartition by Cassandra Replica Deterministic (SPARKC-278)
- Improved performance by caching converters and Java driver codecs.
  (SPARKC-383)
- Added support for driver.LocalDate (SPARKC-385)
- Accept predicates with indexed partition columns (SPARKC-348)
- Retry schema checks to avoid Java Driver debouncing (SPARKC-379)
- Fix compatibility with Cassandra 2.1.X with Single Partitions/In queries.
  (SPARKC-376)
- Use executeAsync while joining with C\* table (SPARKC-233)
- Fix support for C\* Tuples in Dataframes (SPARKC-357)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3407205/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3407205,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.0,v1.6.0,False,False
3304690,2016-05-25T15:29:42Z,2016-05-25T15:56:51Z,Release 1.4.4,"1.4.4
- Use executeAsync when joining with C\* table (SPARKC-233)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3304690/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3304690,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.4,v1.4.4,False,False
3171208,2016-05-06T08:17:36Z,2016-05-06T09:52:37Z,Release 1.4.3,"1.4.3
- Disable delayed retrying (SPARKC-360)
- Improve DataFrames ErrorIfExists Message (SPARKC-338)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3171208/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3171208,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.3,v1.4.3,False,False
3020277,2016-04-14T13:29:13Z,2016-04-14T14:52:20Z,Preview release 1.6.0-M2,"1.6.0 M2
- Performance improvement: keyBy creates an RDD with CassandraPartitioner.
  so shuffling can be avoided in many cases, e.g. when keyBy is followed
  by groupByKey or join (SPARKC-330)
- Improved exception message when data frame is to be saved in.
  non-empty Cassandra table (SPARKC-338)
- Support for Joda time for Cassandra date type (SPARKC-342)
- Don't double resolve the paths for port locks in embedded C*.
  (contribution by crakjie)
- Drop indices that cannot be used in predicate pushdown (SPARKC-347)
- Added support for IF NOT EXISTS (SPARKC-362)
- Nested Optional Case Class can be save as UDT (SPARKC-346)
- Merged Java API into main module (SPARKC-335)
- Upgraded to Spark 1.6.1 (SPARKC-344)
- Fix NoSuchElementException when fetching database schema from Cassandra
  (SPARKC-341)
- Removed the ability to specify cluster alias directly and added some helper methods.
  which make it easier to configure Cassandra related data frames (SPARKC-289)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3020277/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/3020277,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.0-M2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.0-M2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.0-M2,v1.6.0-M2,False,True
2663616,2016-02-22T16:30:16Z,2016-02-22T16:32:30Z,Preview release 1.6.0-M1,"1.6.0 M1
- Adds the ability to add additional Predicate Pushdown Rules at Runtime (SPARKC-308).
- Added CassandraOption for Skipping Columns when Writing to C\* (SPARKC-283)
- Upgrade Spark to 1.6.0 and add Apache Snapshot repository to resolvers (SPARKC-272, SPARKC-298, SPARKC-305)
- Includes all patches up to 1.5.0.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2663616/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2663616,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.6.0-M1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.6.0-M1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.6.0-M1,v1.6.0-M1,False,True
2662380,2016-02-22T13:35:09Z,2016-02-22T14:01:39Z,Release 1.5.0,"1.5.0
- Fixed assembly build (SPARKC-311)
- Upgrade Cassandra version to 3.0.2 by default and allow to specify arbitrary Cassandra version for
  integration tests through the command line (SPARKC-307)
- Upgrade Cassandra driver to 3.0.0 GA
- Includes all patches up to 1.4.2.

1.4.2
- SqlRowWriter not using Cached Converters (SPARKC-329)
- Fix Violation of Partition Contract (SPARKC-323)
- Use ScalaReflectionLock from Spark instead of TypeTag.
  to workaround Scala 2.10 reflection concurrency issues (SPARKC-333)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2662380/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2662380,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.0,v1.5.0,False,False
2632388,2016-02-17T14:20:54Z,2016-02-17T14:33:58Z,Release 1.4.2,"1.4.2
- SqlRowWriter not using Cached Converters (SPARKC-329)
- Fix Violation of Partition Contract (SPARKC-323)
- Use ScalaReflectionLock from Spark instead of TypeTag.
  to workaround Scala 2.10 reflection concurrency issues (SPARKC-333)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2632388/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2632388,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.2,v1.4.2,False,False
2386377,2016-01-07T09:09:56Z,2016-01-07T09:30:49Z,Release 1.5.0 Release Candidate 1,"1.5.0 RC1
- Fix special case types in SqlRowWriter (SPARKC-306)
- Fix sbt assembly
- Create Cassandra Schema from DataFrame (SPARKC-231)
- JWCT inherits Spark Conf from Spark Context (SPARKC-294)
- Support of new Cassandra Date and Time types (SPARKC-277)
- Upgrade Cassandra driver to 3.0.0-rc1
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2386377/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2386377,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.0-RC1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.0-RC1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.0-RC1,v1.5.0-RC1,False,True
2212651,2015-12-01T11:18:05Z,2015-12-01T11:51:11Z,Preview release 1.5.0-M3,"1.5.0 M3.
- Added ColumRef child class to represent functions calls (SPARKC-280)
- Warn if Keep_alive_ms is less than spark batch size in streaming (SPARKC-228)
- Fixed real tests (SPARKC-247)
- Added support for tinyint and smallint types (SPARKC-269)
- Updated Java driver version to 3.0.0-alpha4; Codec API changes (SPARKC-285)
- Updated Java driver version to 3.0.0-alpha3 (SPARKC-270)
- Changed the way CassandraConnectorSource is obtained due to SPARK-7171 (SPARKC-268)
- Change write ConsistencyLevel to LOCAL_QUORUM (SPARKC-262)
- Parallelize integration tests (SPARKC-293)
- Includes all patches up to 1.4.1.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2212651/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2212651,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.0-M3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.0-M3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.0-M3,v1.5.0-M3,False,True
2212449,2015-12-01T10:11:17Z,2015-12-01T11:14:14Z,Release 1.4.1,"1.4.1
- Let UDTs be converted from GenericRows (SPARKC-271)
- Map InetAddress and UUID to string and store it as StringType in Spark SQL (SPARKC-259)
- VarInt Column is converted to decimal stored in Spark SQL (SPARKC-266)
- Retrieve TableSize from Cassandra system table for datasource relation (SPARKC-164)
- Fix merge strategy for netty.io.properties (SPARKC-249)
- Upgrade integration tests to use Cassandra 2.1.9 and upgrade Java Driver.
  to 2.1.7.1, Spark to 1.4.1 (SPARKC-248)
- Make OptionConverter handle Nones as well as nulls (SPARKC-275)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2212449/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/2212449,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.1,v1.4.1,False,False
1911575,2015-10-05T12:30:08Z,2015-10-05T13:05:49Z,Preview release 1.5.0-M2,"1.5.0 M2
- Bump Java Driver to 2.2.0-rc3, Guava to 16.0.1 and test against Cassandra 2.2.1 (SPARKC-229)
- Includes all patches up to 1.4.0.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1911575/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1911575,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.0-M2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.0-M2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.0-M2,v1.5.0-M2,False,True
1910909,2015-10-05T10:25:23Z,2015-10-05T10:58:15Z,Release 1.3.1,"1.3.1
- Remove wrapRDD from CassandraTableScanJavaRDD. Fixes exception occuring
  when performing RDD operations on any CassandraTableScanJavaRDD (SPARKC-236)
- Backport synchronization fixes from 1.4.0 (SPARKC-247)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1910909/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1910909,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.3.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.3.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.3.1,v1.3.1,False,False
1830235,2015-09-17T18:40:27Z,2015-09-17T18:59:26Z,Release 1.4.0 ,"The first stable release of 1.4 branch.

1.4.0
- Fixed broken integration tests (SPARKC-247):
  - Fixed Scala reflection race condition in TupleColumnMapper.
  - Fixed dev/run-real-tests script.
  - Fixed CheckpointStreamSpec test.

1.4.0 RC1
- Added TTL and WRITETIME documentation (SPARKC-244)
- Reduced the amount of unneccessary error logging in integration tests (SPARKC-223)
- Fixed Repartition and JWC and Streaming Checkpointing broken by serialization
  errors related to passing RowWriteFactory / DefaultRowWriter (SPARKC-202)
- Fixed exceptions occuring when performing RDD operations on any.
  CassandraTableScanJavaRDD (SPARKC-236)

1.4.0 M3
- Fixed UDT column bug in SparkSQL (SPARKC-219)
- Includes all patches up to release 1.2.5 and 1.3.0
  - Fixed connection caching, changed SSL EnabledAlgorithms to Set (SPARKC-227)

1.4.0 M2
- Includes some unreleased patches from 1.2.5
  - Changed default query timeout from 12 seconds to 2 minutes (SPARKC-220)
  - Add a configurable delay between subsequent query retries (SPARKC-221)
  - spark.cassandra.output.throughput_mb_per_sec can now be set to a decimal (SPARKC-226)
- Includes unreleased patches from 1.3.0
  - Remove white spaces in c\* connection host string (fix by Noorul Islam K M)
- Includes all changes up to 1.3.0-RC1.

1.4.0 M1
- Upgrade Spark to 1.4.0 (SPARKC-192)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1830235/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1830235,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.0,v1.4.0,False,False
1820399,2015-09-16T08:35:26Z,2015-09-16T08:37:19Z,Release 1.4.0 Candidate 1,"1.4.0 RC1
- Added TTL and WRITETIME documentation (SPARKC-244)
- Reduced the amount of unneccessary error logging in integration tests (SPARKC-223)
- Fixed Repartition and JWC and Streaming Checkpointing broken by serialization
  errors related to passing RowWriteFactory / DefaultRowWriter (SPARKC-202)
- Fixed exceptions occuring when performing RDD operations on any.
  CassandraTableScanJavaRDD (SPARKC-236)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1820399/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1820399,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.0-RC1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.0-RC1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.0-RC1,v1.4.0-RC1,False,True
1798535,2015-09-11T08:14:14Z,2015-09-11T08:29:59Z,Preview release 1.5.0-M1,"This release adds compatibility with Spark 1.5.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1798535/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1798535,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.5.0-M1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.5.0-M1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.5.0-M1,v1.5.0-M1,False,True
1642299,2015-08-07T13:31:43Z,2015-08-07T13:43:09Z,Release 1.4.0 Milestone 3,"1.4.0 M3
- Fixed UDT column bug in SparkSQL (SPARKC-219)
- Includes all patches up to release 1.2.5 and 1.3.0
  - Fixed connection caching, changed SSL EnabledAlgorithms to Set (SPARKC-227)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1642299/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1642299,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.0-M3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.0-M3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.0-M3,v1.4.0-M3,False,True
1641414,2015-08-07T09:17:06Z,2015-08-07T09:48:47Z,Release 1.2.5,"1.2.5
- Changed default query timeout from 12 seconds to 2 minutes (SPARKC-220)
- Add a configurable delay between subsequent query retries (SPARKC-221)
- spark.cassandra.output.throughput_mb_per_sec can now be set to a decimal (SPARKC-226)
- Fixed connection caching, changed SSL EnabledAlgorithms to Set (SPARKC-227)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1641414/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1641414,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.5,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.5,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.5,v1.2.5,False,False
1641292,2015-08-07T07:58:50Z,2015-08-07T09:13:15Z,Release 1.3.0,"1.3.0
- Remove white spaces in c\* connection host string (fix by Noorul Islam K M)
- Included from 1.2.5
  - Changed default query timeout from 12 seconds to 2 minutes (SPARKC-220)
  - Add a configurable delay between subsequent query retries (SPARKC-221)
  - spark.cassandra.output.throughput_mb_per_sec can now be set to a decimal (SPARKC-226)
  - Fixed Connection Caching, Changed SSL EnabledAlgorithms to Set (SPARKC-227)

1.3.0 RC1
- Fixed NoSuchElementException when using UDTs in SparkSQL (SPARKC-218)

1.3.0 M2
- Support for loading, saving and mapping Cassandra tuples (SPARKC-172)
- Support for mapping case classes to UDTs on saving (SPARKC-190)
- Table and keyspace Name suggestions in DataFrames API (SPARKC-186)
- Removed thrift completely (SPARKC-94)
  - removed cassandra-thrift.jar dependency
  - automatic split sizing based on system.size_estimates table
  - add option to manually force the number of splits
  - Cassandra listen addresses fetched from system.peers table
  - spark.cassandra.connection.(rpc|native).port replaced with spark.cassandra.connection.port
- Refactored ColumnSelector to avoid circular dependency on TableDef (SPARKC-177)
- Support for modifying C\* Collections using saveToCassandra (SPARKC-147)
- Added the ability to use Custom Mappers with repartitionByCassandraReplica (SPARKC-104)
- Added methods to work with tuples in Java API (SPARKC-206)
- Fixed input_split_size_in_mb property (SPARKC-208)
- Fixed DataSources tests when connecting to an external cluster (SPARKC-178)
- Added Custom UUIDType and InetAddressType to Spark Sql data type mapping (SPARKC-129)
- Removed CassandraRelation by CassandraSourceRelation and Added cache to
  CassandraCatalog (SPARKC-163)

1.3.0 M1
- Removed use of Thrift describe_ring and replaced it with native Java Driver
  support for fetching TokenRanges (SPARKC-93)
- Support for converting Cassandra UDT column values to Scala case-class objects (SPARKC-4)
  - Introduced a common interface for TableDef and UserDefinedType
  - Removed ClassTag from ColumnMapper
  - Removed by-index column references and replaced them with by-name ColumnRefs
  - Created a GettableDataToMappedTypeConverter that can handle UDTs
  - ClassBasedRowReader delegates object conversion instead of doing it by itself;
    this improves unit-testability of code
- Decoupled PredicatePushDown logic from Spark (SPARKC-166)
  - added support for Filter and Expression predicates
  - improved code testability and added unit-tests
- Basic Datasource API integration and keyspace/cluster level settings (SPARKC-112, SPARKC-162)
- Added support to use aliases with Tuples (SPARKC-125)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1641292/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1641292,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.3.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.3.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.3.0,v1.3.0,False,False
1601493,2015-07-29T11:32:29Z,2015-07-29T12:17:22Z,Release 1.4.0 Milestone 2,"1.4.0 M2
- (pulled) Changed default query timeout from 12 seconds to 2 minutes (SPARKC-220)
- (pulled) Add a configurable delay between subsequent query retries (SPARKC-221)
- (pulled) All 1.3.0-M2 and 1.3.0-RC1 changes.

1.3.0 RC1
- Fixed NoSuchElementException when using UDTs in SparkSQL (SPARKC-218)

1.3.0 M2
- Support for loading, saving and mapping Cassandra tuples (SPARKC-172)
- Support for mapping case classes to UDTs on saving (SPARKC-190)
- Table and keyspace Name suggestions in DataFrames API (SPARKC-186)
- Removed thrift completely (SPARKC-94)
  - removed cassandra-thrift.jar dependency
  - automatic split sizing based on system.size_estimates table
  - add option to manually force the number of splits
  - Cassandra listen addresses fetched from system.peers table
  - spark.cassandra.connection.(rpc|native).port replaced with spark.cassandra.connection.port
- Refactored ColumnSelector to avoid circular dependency on TableDef (SPARKC-177)
- Support for modifying C\* Collections using saveToCassandra (SPARKC-147)
- Added the ability to use Custom Mappers with repartitionByCassandraReplica (SPARKC-104)
- Added methods to work with tuples in Java API (SPARKC-206)
- Fixed input_split_size_in_mb property (SPARKC-208)
- Fixed DataSources tests when connecting to an external cluster (SPARKC-178)
- Added Custom UUIDType and InetAddressType to Spark Sql data type mapping (SPARKC-129)
- Removed CassandraRelation by CassandraSourceRelation and Added cache to
  CassandraCatalog (SPARKC-163)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1601493/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1601493,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.0-M2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.0-M2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.0-M2,v1.4.0-M2,False,True
1571261,2015-07-22T10:35:48Z,2015-07-22T15:07:30Z,Release 1.2.4,"1.2.4
- Cassandra native count is performed by `cassandraCount` method (SPARKC-215)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1571261/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1571261,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.4,v1.2.4,False,False
1569877,2015-07-22T09:00:06Z,2015-07-22T10:12:01Z,Release 1.3.0 Candidate 1,"Hopefully the first and only RC in 1.3.x series.

1.3.0 RC1
- Fixed NoSuchElementException when using UDTs in SparkSQL (SPARKC-218)

1.2.4
- Cassandra native count is performed by `cassandraCount` method (SPARKC-215)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1569877/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1569877,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.3.0-RC1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.3.0-RC1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.3.0-RC1,v1.3.0-RC1,False,True
1474908,2015-06-29T19:52:35Z,2015-06-29T20:15:32Z,Release 1.3.0 Milestone 2,"1.3.0 M2
- Support for loading, saving and mapping Cassandra tuples (SPARKC-172)
- Support for mapping case classes to UDTs on saving (SPARKC-190)
- Table and keyspace Name suggestions in DataFrames API (SPARKC-186)
- Removed thrift completely (SPARKC-94)
  - removed cassandra-thrift.jar dependency
  - automatic split sizing based on system.size_estimates table
  - add option to manually force the number of splits
  - Cassandra listen addresses fetched from system.peers table
  - spark.cassandra.connection.(rpc|native).port replaced with spark.cassandra.connection.port
- Refactored ColumnSelector to avoid circular dependency on TableDef (SPARKC-177)
- Support for modifying C\* Collections using saveToCassandra (SPARKC-147)
- Added the ability to use Custom Mappers with repartitionByCassandraReplica (SPARKC-104)
- Added methods to work with tuples in Java API (SPARKC-206)
- Fixed input_split_size_in_mb property (SPARKC-208)
- Fixed DataSources tests when connecting to an external cluster (SPARKC-178)
- Added Custom UUIDType and InetAddressType to Spark Sql data type mapping (SPARKC-129)
- Removed CassandraRelation by CassandraSourceRelation and Added cache to
  CassandraCatalog (SPARKC-163)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1474908/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1474908,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.3.0-M2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.3.0-M2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.3.0-M2,v1.3.0-M2,False,True
1474833,2015-06-29T18:59:48Z,2015-06-29T19:56:53Z,Release 1.2.3,"1.2.3
- Support for connection compressions configuration (SPARKC-124)
- Support for connection encryption configuration (SPARKC-118)
- Fix a bug to support upper case characters in UDT (SPARKC-201)
- Meaningful exception if some partition key column is null (SPARKC-198)
- Improved reliability of thread-leak test (SPARKC-205)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1474833/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1474833,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.3,v1.2.3,False,False
1410451,2015-06-12T19:19:57Z,2015-06-12T19:28:23Z,Release 1.4.0 Milestone 1,"This preview release brings compatibility with Spark 1.4.0.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1410451/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1410451,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.4.0-M1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.4.0-M1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.4.0-M1,v1.4.0-M1,False,True
1362141,2015-06-01T16:35:15Z,2015-06-01T16:44:06Z,Release 1.3.0 Milestone 1,"1.3.0 M1
- Removed use of Thrift describe_ring and replaced it with native Java Driver
  support for fetching TokenRanges (SPARKC-93)
- Support for converting Cassandra UDT column values to Scala case-class objects (SPARKC-4)
  - Introduced a common interface for TableDef and UserDefinedType
  - Removed ClassTag from ColumnMapper
  - Removed by-index column references and replaced them with by-name ColumnRefs
  - Created a GettableDataToMappedTypeConverter that can handle UDTs
  - ClassBasedRowReader delegates object conversion instead of doing it by itself;
    this improves unit-testability of code
- Decoupled PredicatePushDown logic from Spark (SPARKC-166)
  - added support for Filter and Expression predicates
  - improved code testability and added unit-tests
- Basic Datasource API integration and keyspace/cluster level settings (SPARKC-112, SPARKC-162)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1362141/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1362141,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.3.0-M1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.3.0-M1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.3.0-M1,v1.3.0-M1,False,True
1361985,2015-06-01T16:04:40Z,2015-06-01T16:07:18Z,Release 1.2.2,"1.2.2
- Updated Spark version to 1.2.2, Scala to 2.10.5 / 2.11.6
- Enabled Java API artifact generation for Scala 2.11.x (SPARKC-130)
- Fixed a bug preventing a custom type converter from being used
  when saving data. RowWriter implementations must
  perform type conversions now. (SPARKC-157)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1361985/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1361985,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.2,v1.2.2,False,False
1361272,2015-06-01T13:10:10Z,2015-06-01T13:59:10Z,Release 1.1.2,"1.1.2
- Backport SPARKC-8, retrieval of TTL and write time
- Upgraded to Spark 1.1.1
- Synchronized ReflectionUtil findScalaObject and findSingletonClassInstance methods
  to avoid problems with Scala 2.10 lack thread safety in the reflection subsystem (SPARKC-107)
- Fixed populating ReadConf with properties from SparkConf (SPARKC-121)
- Adds both hostname and hostaddress as partition preferredLocations (SPARKC-141, backport of SPARKC-126)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1361272/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1361272,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.2,v1.1.2,False,False
1300090,2015-05-15T10:02:22Z,2015-05-15T10:23:06Z,Release 1.2.1,"1.2.1
- Fixed problems with mixed case keyspaces in ReplicaMapper (SPARKC-159)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1300090/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1300090,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.1,v1.2.1,False,False
1255262,2015-05-04T19:56:58Z,2015-05-04T20:33:28Z,Release 1.2.0,"1.2.0
- Removed conversion method rom WriteOption which accepted object of Duration type
  from Spark Streaming (SPARKC-106)
- Fixed compilation warnings (SPARKC-76)
- Fixed ScalaDoc warnings (SPARKC-119)
- Synchronized TypeTag access in various places (SPARKC-123)
- Adds both hostname and hostaddress as partition preferredLocations (SPARKC-126)

1.2.0 RC 3
- Select aliases are no longer ignored in CassandraRow objects (SPARKC-109)
- Fix picking up username and password from SparkConf (SPARKC-108)
- Fix creating CassandraConnectorSource in the executor environment (SPARKC-111)

1.2.0 RC 2
- Cross cluster table join and write for Spark SQL (SPARKC-73)
- Enabling / disabling metrics in metrics configuration file and other metrics fixes (SPARKC-91)
- Provided a way to set custom auth config and connection factory properties (SPARKC-105)
- Fixed setting custom connection factory and other properties (SPAKRC-102)
- Fixed Java API (SPARKC-95)

1.2.0 RC 1
- More Spark SQL predicate push (SPARKC-72)
- Fixed some Java API problems and refactored its internals (SPARKC-77)
- Allowing specification of column to property map (aliases) for reading and writing objects
  (SPARKC-9)
- Added interface for doing primary key joins between arbitrary RDDs and Cassandra (SPARKC-25)
- Added method for repartitioning an RDD based upon the replication of a Cassandra Table (SPARKC-25)
- Fixed setting batch.level and batch.buffer.size in SparkConf. (SPARKC-84)
  - Renamed output.batch.level to output.batch.grouping.key.
  - Renamed output.batch.buffer.size to output.batch.grouping.buffer.size.
  - Renamed batch grouping key option ""all"" to ""none"".
- Error out on invalid config properties (SPARKC-90)
- Set Java driver version to 2.1.5 and Cassandra to 2.1.3 (SPARKC-92)
- Moved Spark streaming related methods from CassandraJavaUtil to CassandraStreamingJavaUtil
  (SPARKC-80)

1.2.0 alpha 3
- Exposed spanBy and spanByKey in Java API (SPARKC-39)
- Added automatic generation of Cassandra table schema from a Scala type and
  saving an RDD to a new Cassandra table by saveAsCassandraTable method (SPARKC-38)
- Added support for write throughput limiting (SPARKC-57)
- Added EmptyCassandraRDD (SPARKC-37)
- Exposed authConf in CassandraConnector
- Overridden count() implementation in CassandraRDD which uses native Cassandra count (SPARKC-52)
- Removed custom Logging class (SPARKC-54)
- Added support for passing the limit clause to CQL in order to fetch top n results (SPARKC-31)
- Added support for pushing down order by clause for explicitly specifying an order of rows within
  Cassandra partition (SPARKC-32)
- Fixed problems when rows are mapped to classes with inherited fields (SPARKC-70)
- Support for compiling with Scala 2.10 and 2.11 (SPARKC-22)

1.2.0 alpha 2
- All connection properties can be set on SparkConf / CassandraConnectorConf objects and
  the settings are automatically distributed to Spark Executors (SPARKC-28)
- Report Connector metrics to Spark metrics system (SPARKC-27)
- Upgraded to Spark 1.2.1 (SPARKC-30)
- Add conversion from java.util.Date to java.sqlTimestamp for Spark SQL (#512)
- Upgraded to Scala 2.11 and scala version cross build (SPARKC-22)

1.2.0 alpha 1
- Added support for TTL and timestamp in the writer (#153)
- Added support for UDT column types (SPARKC-1)
- Upgraded Spark to version 1.2.0 (SPARKC-15)
- For 1.2.0 release, table name with dot is not supported for Spark SQL,
  it will be fixed in the next release
- Added fast spanBy and spanByKey methods to RDDs useful for grouping Cassandra
  data by partition key / clustering columns. Useful for e.g. time-series data. (SPARKC-2)
- Refactored the write path so that the writes are now token-aware (S
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1255262/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1255262,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0,v1.2.0,False,False
1109888,2015-03-31T10:27:12Z,2015-03-31T11:04:24Z,Preview Release 1.2.0 RC 3,"1.2.0 RC 3
- Select aliases are no longer ignored in CassandraRow objects (SPARKC-109)
- Fix picking up username and password from SparkConf (SPARKC-108)
- Fix creating CassandraConnectorSource in the executor environment (SPARKC-111)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1109888/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1109888,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0-rc3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0-rc3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0-rc3,v1.2.0-rc3,False,True
1097729,2015-03-27T11:39:52Z,2015-03-27T12:08:49Z,Preview Release 1.2.0 RC 2,"1.2.0 RC 2
- Cross cluster table join and write for Spark SQL (SPARKC-73)
- Enabling / disabling metrics in metrics configuration file and other metrics fixes (SPARKC-91)
- Provided a way to set custom auth config and connection factory properties (SPARKC-105)
- Fixed setting custom connection factory and other properties (SPAKRC-102)
- Fixed Java API (SPARKC-95)

1.1.x (unreleased)
- Synchronized ReflectionUtil findScalaObject and findSingletonClassInstance methods
  to avoid problems with Scala 2.10 lack thread safety in the reflection subsystem (SPARKC-107)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1097729/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1097729,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0-rc2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0-rc2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0-rc2,v1.2.0-rc2,False,True
1068339,2015-03-19T13:07:13Z,2015-03-19T13:08:29Z,Preview Release 1.2.0 RC 1,"1.2.0 rc 1
- More Spark SQL predicate push (SPARKC-72)
- Fixed some Java API problems and refactored its internals (SPARKC-77)
- Allowing specification of column to property map (aliases) for reading and writing objects
  (SPARKC-9)
- Added interface for doing primary key joins between arbitrary RDDs and Cassandra (SPARKC-25)
- Added method for repartitioning an RDD based upon the replication of a Cassandra Table (SPARKC-25)
- Fixed setting batch.level and batch.buffer.size in SparkConf. (SPARKC-84)
  - Renamed output.batch.level to output.batch.grouping.key.
  - Renamed output.batch.buffer.size to output.batch.grouping.buffer.size.
  - Renamed batch grouping key option ""all"" to ""none"".
- Error out on invalid config properties (SPARKC-90)
- Set Java driver version to 2.1.5 and Cassandra to 2.1.3 (SPARKC-92)
- Moved Spark streaming related methods from CassandraJavaUtil to CassandraStreamingJavaUtil 
  (SPARKC-80)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1068339/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1068339,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0-rc1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0-rc1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0-rc1,v1.2.0-rc1,False,True
1022389,2015-03-06T10:10:55Z,2015-03-06T10:34:04Z,Preview Release 1.2.0 alpha 3,"1.2.0 alpha 3
- Exposed spanBy and spanByKey in Java API (SPARKC-39)
- Added automatic generation of Cassandra table schema from a Scala type and
  saving an RDD to a new Cassandra table by saveAsCassandraTable method (SPARKC-38)
- Added support for write throughput limiting (SPARKC-57)
- Added EmptyCassandraRDD (SPARKC-37)
- Exposed authConf in CassandraConnector
- Overridden count() implementation in CassandraRDD which uses native Cassandra count (SPARKC-52)
- Removed custom Logging class (SPARKC-54)
- Added support for passing the limit clause to CQL in order to fetch top n results (SPARKC-31)
- Added support for pushing down order by clause for explicitly specifying an order of rows within
  Cassandra partition (SPARKC-32)
- Fixed problems when rows are mapped to classes with inherited fields (SPARKC-70)
- Support for compiling with Scala 2.10 and 2.11 (SPARKC-22)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1022389/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/1022389,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0-alpha3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0-alpha3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0-alpha3,v1.2.0-alpha3,False,True
940916,2015-02-11T10:23:44Z,2015-02-11T10:39:43Z,Preview Release 1.2.0 alpha 2,"Changes since 1.2.0 alpha 1:

1.2.0 alpha 2
- All connection properties can be set on SparkConf / CassandraConnectorConf objects and
  the settings are automatically distributed to Spark Executors (SPARKC-28)
- Report Connector metrics to Spark metrics system (SPARKC-27)
- Upgraded to Spark 1.2.1 (SPARKC-30)
- Add conversion from java.util.Date to java.sqlTimestamp for Spark SQL (#512)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/940916/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/940916,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/1.2.0-alpha2,https://github.com/datastax/spark-cassandra-connector/releases/tag/1.2.0-alpha2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/1.2.0-alpha2,1.2.0-alpha2,False,True
858885,2015-01-16T16:01:57Z,2015-01-16T17:25:53Z,Preview Release 1.2.0 alpha 1,"1.2.0 alpha 1
- Added support for TTL and timestamp in the writer (#153)
- Added support for UDT column types (SPARKC-1)
- Upgraded Spark to version 1.2.0 (SPARKC-15)
- For 1.2.0 release, table name with dot is not supported for Spark SQL,
  it will be fixed in the next release
- Added fast spanBy and spanByKey methods to RDDs useful for grouping Cassandra
  data by partition key / clustering columns. Useful for e.g. time-series data. (SPARKC-2)
- Refactored the write path so that the writes are now token-aware (SPARKC-5, previously #442)
- Added support for INSET predicate pushdown (patch by granturing)

Note this is a preview release and it may not be source nor binary compatible with next 1.2 releases.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/858885/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/858885,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.2.0-alpha1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.2.0-alpha1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.2.0-alpha1,v1.2.0-alpha1,False,True
850414,2015-01-14T09:35:25Z,2015-01-14T10:06:40Z,Release 1.0.6,"1.0.6
- Upgraded Java Driver to 2.0.8 and added some logging in LocalNodeFirstLoadBalancingPolicy (SPARKC-18)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/850414/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/850414,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.6,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.6,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.6,v1.0.6,False,False
813320,2014-12-29T13:37:24Z,2014-12-29T13:50:07Z,Release 1.1.1,"1.1.1
- Fixed NoSuchElementException in SparkSQL predicate pushdown code (SPARKC-7, #454)

Also includes a fix from 1.0.5:
- Fixed setting output consistency level which was being set on prepared
  statements instead of being set on batches (#463)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/813320/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/813320,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.1,v1.1.1,False,False
813067,2014-12-29T10:59:19Z,2014-12-29T11:13:13Z,Release 1.0.5,"1.0.5
- Fixed setting output consistency level which was being set on prepared
  statements instead of being set on batches (#463)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/813067/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/813067,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.5,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.5,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.5,v1.0.5,False,False
729988,2014-11-24T19:03:42Z,2014-11-24T19:11:07Z,Release 1.1.0,"Changes since 1.0.x:

1.1.0
- Switch to java driver 2.1.3 and Guava 14.0.1 (yay!).

1.1.0 rc 3
- Fix NPE when saving CassandraRows containing null values (#446)

1.1.0 rc 2
- Added JavaTypeConverter to make is easy to implement custom TypeConverter in Java (#429)
- Fix SparkSQL failures caused by presence of non-selected columns of UDT type in the table.

1.1.0 rc 1
- Fixed problem with setting a batch size in bytes (#435)
- Fixed handling of null column values in Java API (#429)

1.1.0 beta 2
- Fixed bug in Java API which might cause ClassNotFoundException
- Added stubs for UDTs. It is possible to read tables with UDTs, but
  values of UDTs will come out as java driver UDTValue objects (#374)
- Upgraded Java driver to 2.1.2 version and fixed deprecation warnings.
  Use correct protocolVersion when serializing/deserializing Cassandra columns.
- Don't fail with ""contact points contain multiple datacenters""
  if one or more of the nodes given as contact points don't have DC information,
  because they are unreachable.
- Removed annoying slf4j warnings when running tests (#395)
- CassandraRDD is fully lazy now - initialization no longer fetches Cassandra
  schema (#339).

1.1.0 beta 1
- Redesigned Java API, some refactorings (#300)
- Simplified AuthConf - more responsibility on CassandraConnectionFactory
- Enhanced and improved performance of the embedded Kafka framework
  - Kafka consumer and producer added that are configurable
  - Kafka shutdown cleaned up
  - Kafka server more configurable for speed and use cases
- Added new word count demo and a new Kafka streaming word count demo
- Modified build file to allow easier module id for usages of 'sbt project'

1.1.0 alpha 4
- Use asynchronous prefetching of multi-page ResultSets in CassandraRDD
  to reduce waiting for Cassandra query results.
- Make token range start and end be parameters of the query, not part of the query
  template to reduce the number of statements requiring preparation.
- Added type converter for GregorianCalendar (#334)

1.1.0 alpha 3
- Pluggable mechanism for obtaining connections to Cassandra
  Ability to pass custom CassandraConnector to CassandraRDDs (#192)
- Provided a row reader which allows to create RDDs of pairs of objects as well
  as RDDs of simple objects handled by type converter directly;
  added meaningful compiler messages when invalid type was provided (#88)
- Fixed serialization problem in CassandraSQLContext by making conf transient (#310)
- Cleaned up the SBT assembly task and added build documentation (#315)

1.1.0 alpha 2
- Upgraded Apache Spark to 1.1.0.
- Upgraded to be Cassandra 2.1.0 and Cassandra 2.0 compatible.
- Added spark.cassandra.connection.local_dc option
- Added spark.cassandra.connection.timeout_ms option
- Added spark.cassandra.read.timeout_ms option
- Added support for SparkSQL (#197)
- Fixed problems with saving DStreams to Cassandra directly (#280)

1.1.0 alpha 1
- Add an ./sbt/sbt script (like with spark) so people don't need to install sbt
- Replace internal spark Logging with own class (#245)
- Accept partition key predicates in CassandraRDD#where. (#37)
- Add indexedColumn to ColumnDef (#122)
- Upgrade Spark to version 1.0.2
- Removed deprecated toArray, replaced with collect.
- Updated imports to org.apache.spark.streaming.receiver
  and import org.apache.spark.streaming.receiver.ActorHelper
- Updated streaming demo and spec for Spark 1.0.2 behavior compatibility
- Added new StreamingEvent types for Spark 1.0.2 Receiver readiness
- Added the following Spark Streaming dependencies to the demos module:
  Kafka, Twitter, ZeroMQ
- Added embedded Kafka and ZooKeeper servers for the Kafka Streaming demo
  - keeping non private for user prototyping
- Added new Kafka Spark Streaming demo which reads from Kafka
  and writes to Cassandra (Twitter and ZeroMQ are next)
- Added new 'embedded' module
  - Refactored the 'connector' module's IT SparkRepl, CassandraServer and
    CassandraServerRunner as well as 'demos' EmbeddedKafka
    and EmbeddedZookeeper to the 'embedded' module. This allows the 'embedded'
    module to be used as a dependency by the 'connector' IT tests, demos,
    and user local quick prototyping without requiring a Spark and Cassandra
    Cluster, local or remote, to get started.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/729988/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/729988,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0,v1.1.0,False,False
728753,2014-11-23T17:30:33Z,2014-11-24T11:54:29Z,1.1.0 Release Candidate 2,"1.1.0 rc 2
- Added JavaTypeConverter to make is easy to implement custom TypeConverter in Java (#429)
- Fix SparkSQL failures caused by presence of non-selected columns of UDT type in the table.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/728753/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/728753,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-rc2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-rc2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-rc2,v1.1.0-rc2,False,False
728750,2014-11-24T11:51:53Z,2014-11-24T11:53:47Z,1.1.0 Release Candidate 3,"1.1.0 rc 3
- Fix NPE when saving CassandraRows containing null values (#446)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/728750/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/728750,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-rc3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-rc3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-rc3,v1.1.0-rc3,False,False
721638,2014-11-20T19:13:56Z,2014-11-20T21:11:34Z,1.1.0 Release Candidate 1,"Changes since 1.1.0-beta2:
- Fixed problem with setting a batch size in bytes (#435)
- Fixed handling of null column values in Java API (#429)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/721638/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/721638,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-rc1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-rc1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-rc1,v1.1.0-rc1,False,False
698643,2014-11-12T15:33:50Z,2014-11-12T16:35:27Z,,"1.1.0 beta 2
- Fixed bug in Java API which might cause ClassNotFoundException
- Added stubs for UDTs. It is possible to read tables with UDTs, but
  values of UDTs will come out as java driver UDTValue objects (#374)
- Upgraded Java driver to 2.1.2 version and fixed deprecation warnings.
  Use correct protocolVersion when serializing/deserializing Cassandra columns.
- Don't fail with ""contact points contain multiple datacenters""
  if one or more of the nodes given as contact points don't have DC information,
  because they are unreachable.
- Removed annoying slf4j warnings when running tests (#395)
- CassandraRDD is fully lazy now - initialization no longer fetches Cassandra
  schema (#339).

Also includes changes released in 1.0.4:

1.0.4
- Synchronized TypeConverter.forType methods to workaround some Scala 2.10
  reflection thread-safety problems (#235)
- Synchronized computation of TypeTags in TypeConverter#targetTypeTag,.
  ColumnType#scalaTypeTag methods and other places to workaround some of.
  Scala 2.10 reflection thread-safety problems (#364)
- Downgraded Guava to version 14.
  Upgraded Java driver to 2.0.7.
  Upgraded Cassandra to 2.0.11. (#366)
- Made SparkContext variable transient in SparkContextFunctions (#373)
- Fixed saving to tables with uppercase column names (#377)
- Fixed saving collections of Tuple1 (#420)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/698643/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/698643,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-beta2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-beta2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-beta2,v1.1.0-beta2,False,True
685815,2014-11-07T11:12:24Z,2014-11-07T10:18:03Z,Release 1.0.4,"1.0.4
- Synchronized TypeConverter.forType methods to workaround some Scala 2.10
  reflection thread-safety problems (#235)
- Synchronized computation of TypeTags in TypeConverter#targetTypeTag,.
  ColumnType#scalaTypeTag methods and other places to workaround some of.
  Scala 2.10 reflection thread-safety problems (#364)
- Downgraded Guava to version 14.
  Upgraded Java driver to 2.0.7.
  Upgraded Cassandra to 2.0.11. (#366)
- Made SparkContext variable transient in SparkContextFunctions (#373)
- Fixed saving to tables with uppercase column names (#377)
- Fixed saving collections of Tuple1 (#420)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/685815/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/685815,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.4,v1.0.4,False,False
657218,2014-10-27T19:01:36Z,2014-10-27T19:10:03Z,Release 1.1.0 beta 1,"Changes since 1.1.0-alpha4:

1.1.0 beta 1
- Redesigned Java API, some refactorings (#300)
- Simplified AuthConf - more responsibility on CassandraConnectionFactory
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/657218/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/657218,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-beta1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-beta1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-beta1,v1.1.0-beta1,False,True
631765,2014-10-16T15:37:20Z,2014-10-16T16:08:09Z,Preview release 1.1.0 alpha 4,"Changes:
- Use asynchronous prefetching of multi-page ResultSets in CassandraRDD
  to reduce waiting for Cassandra query results.
- Make token range start and end be parameters of the query, not part of the query
  template to reduce the number of statements requiring preparation.
- Added type converter for GregorianCalendar (#334)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/631765/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/631765,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-alpha4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-alpha4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-alpha4,v1.1.0-alpha4,False,True
628127,2014-10-15T12:11:59Z,2014-10-15T12:24:57Z,Release 1.0.3,"1.0.3
- Fixed handling of Cassandra rpc_address set to 0.0.0.0 (#332)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/628127/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/628127,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.3,v1.0.3,False,False
618308,2014-10-10T16:45:56Z,2014-10-10T16:51:12Z,Preview release 1.1.0 alpha 3,"Changes:
- Pluggable mechanism for obtaining connections to Cassandra
  Ability to pass custom CassandraConnector to CassandraRDDs (#192)
- Provided a row reader which allows to create RDDs of pairs of objects as well
  as RDDs of simple objects handled by type converter directly;
  added meaningful compiler messages when invalid type was provided (#88)
- Fixed serialization problem in CassandraSQLContext by making conf transient (#310)
- Cleaned up the SBT assembly task and added build documentation (#315)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/618308/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/618308,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-alpha3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-alpha3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-alpha3,v1.1.0-alpha3,False,True
618251,2014-10-10T16:13:19Z,2014-10-10T16:31:57Z,Release 1.0.2,"Changes:
- Fixed batch counter columns updates (#234, #316)
- Expose both rpc addresses and local addresses of cassandra nodes in partition
  preferred locations (#325)
- Cleaned up the SBT assembly task and added build documentation
  (backport of #315)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/618251/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/618251,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.2,v1.0.2,False,False
612015,2014-10-08T13:38:12Z,2014-10-08T14:12:34Z,Release 1.0.1,"Changes:
- Add logging of error message when asynchronous task fails in AsyncExecutor.
  (#265)
- Fix connection problems with fetching token ranges from hosts with
  rpc_address different than listen_address.
  Log host address(es) and ports on connection failures.
  Close thrift transport if connection fails for some reason after opening the transport,
  e.g. authentication failure.
- Upgrade cassandra driver to 2.0.6.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/612015/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/612015,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.1,v1.0.1,False,False
598523,2014-10-01T14:43:42Z,2014-10-02T11:52:44Z,Preview release 1.1.0 alpha 2,"Changes:
- Upgraded Apache Spark to 1.1.0.
- Upgraded to be Cassandra 2.1.0 and Cassandra 2.0 compatible.
- Added spark.cassandra.connection.local_dc option
- Added spark.cassandra.connection.timeout_ms option
- Added spark.cassandra.read.timeout_ms option
- Added support for SparkSQL (#197)
- Fixed problems with saving DStreams to Cassandra directly (#280)
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/598523/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/598523,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-alpha2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-alpha2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-alpha2,v1.1.0-alpha2,False,True
575975,2014-09-22T15:44:08Z,2014-09-23T07:58:29Z,Preview release 1.1.0 alpha 1,"Warning: This is a preview release - the API might change. 

Version 1.1.0 is intended to be compatible with Spark 1.0.2 and Spark 1.1.x, as well as Cassandra 2.0 and Cassandra 2.1.

Changes from 1.0.0:
- Add an ./sbt/sbt script (like with spark) so people don't need to install sbt
- Replace internal spark Logging with own class (#245)
- Accept partition key predicates in CassandraRDD#where. (#37)
- Add indexedColumn to ColumnDef (#122)
- Upgrade Spark to version 1.0.2.
- Removed deprecated toArray, replaced with collect.
- Updated imports to org.apache.spark.streaming.receiver
  and import org.apache.spark.streaming.receiver.ActorHelper
- Updated streaming demo and spec for Spark 1.0.2 behavior compatibility
- Added new StreamingEvent types for Spark 1.0.2 Receiver readiness
- Added the following Spark Streaming dependencies to the demos module:
  Kafka, Twitter, ZeroMQ
- Added embedded Kafka and ZooKeeper servers for the Kafka Streaming demo
  - keeping non private for user prototyping
- Added new Kafka Spark Streaming demo which reads from Kafka
  and writes to Cassandra (Twitter and ZeroMQ are next)
- Added new 'embedded' module
  - Refactored the 'connector' module's IT SparkRepl, CassandraServer and CassandraServerRunner as
    well as 'demos' EmbeddedKafka and EmbeddedZookeeper to the 'embedded' module. This allows the 'embedded'
    module to be used as a dependency by the 'connector' IT tests, demos, and user local quick prototyping
    without requiring a Spark and Cassandra Cluster, local or remote, to get started.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/575975/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/575975,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.1.0-alpha1,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.1.0-alpha1,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.1.0-alpha1,v1.1.0-alpha1,False,True
566058,2014-09-18T08:20:04Z,2014-09-18T08:36:30Z,Release 1.0.0,"First stable release.
",https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/566058/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/566058,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0,v1.0.0,False,False
537440,2014-09-04T13:27:08Z,2014-09-05T08:46:55Z,Release 1.0.0 RC 6,,https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/537440/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/537440,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0-rc6,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0-rc6,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0-rc6,v1.0.0-rc6,False,False
528425,2014-09-01T19:41:40Z,2014-09-01T19:47:45Z,Release 1.0.0 RC 5,,https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/528425/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/528425,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0-rc5,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0-rc5,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0-rc5,v1.0.0-rc5,False,False
508604,2014-08-12T07:33:24Z,2014-08-22T14:03:26Z,,,https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/508604/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/508604,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0-rc3,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0-rc3,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0-rc3,v1.0.0-rc3,False,False
504246,2014-08-18T13:51:36Z,2014-08-20T20:27:55Z,,,https://api.github.com/users/pkolaczk,1352795,pkolaczk,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/504246/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/504246,master,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0-rc4,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0-rc4,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0-rc4,v1.0.0-rc4,False,False
457808,2014-07-29T14:17:59Z,2014-07-29T14:20:57Z,v1.0.0-rc2,,https://api.github.com/users/jacek-lewandowski,6516951,jacek-lewandowski,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/457808/assets,https://api.github.com/repos/datastax/spark-cassandra-connector/releases/457808,b1.0,https://api.github.com/repos/datastax/spark-cassandra-connector/tarball/v1.0.0-rc2,https://github.com/datastax/spark-cassandra-connector/releases/tag/v1.0.0-rc2,https://api.github.com/repos/datastax/spark-cassandra-connector/zipball/v1.0.0-rc2,v1.0.0-rc2,False,False
