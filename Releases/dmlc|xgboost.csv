id,created_at,published_at,name,body,author_url,author_id,author_login,assets_url,url,target_commitish,tarball_url,html_url,zipball_url,tag_name,draft,prerelease
3772646,2016-07-29T18:23:06Z,2016-07-29T18:25:11Z,This is a stable release of 0.6 version,"# Changes
- Version 0.5 is skipped due to major improvements in the core
- Major refactor of core library.
  - Goal: more flexible and modular code as a portable library.
  - Switch to use of c++11 standard code.
  - Random number generator defaults to `std::mt19937`.
  - Share the data loading pipeline and logging module from dmlc-core.
  - Enable registry pattern to allow optionally plugin of objective, metric, tree constructor, data loader.
    - Future plugin modules can be put into xgboost/plugin and register back to the library.
  - Remove most of the raw pointers to smart ptrs, for RAII safety.
- Add official option to approximate algorithm `tree_method` to parameter.
  - Change default behavior to switch to prefer faster algorithm.
  - User will get a message when approximate algorithm is chosen.
- Change library name to libxgboost.so
- Backward compatiblity
  - The binary buffer file is not backward compatible with previous version.
  - The model file is backward compatible on 64 bit platforms.
- The model file is compatible between 64/32 bit platforms(not yet tested).
- External memory version and other advanced features will be exposed to R library as well on linux.
  - Previously some of the features are blocked due to C++11 and threading limits.
  - The windows version is still blocked due to Rtools do not support `std::thread`.
- rabit and dmlc-core are maintained through git submodule
  - Anyone can open PR to update these dependencies now.
- Improvements
  - Rabit and xgboost libs are not thread-safe and use thread local PRNGs
  - This could fix some of the previous problem which runs xgboost on multiple threads.
- JVM Package
  - Enable xgboost4j for java and scala
  - XGBoost distributed now runs on Flink and Spark.
- Support model attributes listing for meta data.
  - https://github.com/dmlc/xgboost/pull/1198
  - https://github.com/dmlc/xgboost/pull/1166
- Support callback API
  - https://github.com/dmlc/xgboost/issues/892
  - https://github.com/dmlc/xgboost/pull/1211
  - https://github.com/dmlc/xgboost/pull/1264
- Support new booster DART(dropout in tree boosting)
  - https://github.com/dmlc/xgboost/pull/1220
- Add CMake build system
  - https://github.com/dmlc/xgboost/pull/1314
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/3772646/assets,https://api.github.com/repos/dmlc/xgboost/releases/3772646,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.60,https://github.com/dmlc/xgboost/releases/tag/v0.60,https://api.github.com/repos/dmlc/xgboost/zipball/v0.60,v0.60,False,False
2431598,2016-01-14T23:58:02Z,2016-01-15T00:00:42Z,Last version of 0.4x,"This is last version release of 0.4 series, with many changes in the language bindings.

This is also a checkpoint before we switch to xgboost-brick https://github.com/dmlc/xgboost/issues/736

## Changes
- Changes in R library
  - fixed possible problem of poisson regression.
  - switched from 0 to NA for missing values.
  - exposed access to additional model parameters.
- Changes in Python library
  - throws exception instead of crash terminal when a parameter error happens.
  - has importance plot and tree plot functions.
  - accepts different learning rates for each boosting round.
  - allows model training continuation from previously saved model.
  - allows early stopping in CV.
  - allows feval to return a list of tuples.
  - allows eval_metric to handle additional format.
  - improved compatibility in sklearn module.
  - additional parameters added for sklearn wrapper.
  - added pip installation functionality.
  - supports more Pandas DataFrame dtypes. 
  - added best_ntree_limit attribute, in addition to best_score and best_iteration.
- Java api is ready for use
- Added more test cases and continuous integration to make each build more robust.
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/2431598/assets,https://api.github.com/repos/dmlc/xgboost/releases/2431598,master,https://api.github.com/repos/dmlc/xgboost/tarball/0.47,https://github.com/dmlc/xgboost/releases/tag/0.47,https://api.github.com/repos/dmlc/xgboost/zipball/0.47,0.47,False,False
1285564,2015-05-12T06:44:02Z,2015-05-12T06:45:05Z,XGBoost-0.4-0,"This is a stable release of 0.4 version
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/1285564/assets,https://api.github.com/repos/dmlc/xgboost/releases/1285564,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.40,https://github.com/dmlc/xgboost/releases/tag/v0.40,https://api.github.com/repos/dmlc/xgboost/zipball/v0.40,v0.40,False,False
541478,2014-09-07T23:48:45Z,2014-09-08T01:06:01Z,XGBoost-0.3-2,"This is stable version release, corresponding to the R-package xgboost-0.3-2. With new demo folder for detailed walk through.
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/541478/assets,https://api.github.com/repos/dmlc/xgboost/releases/541478,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.32,https://github.com/dmlc/xgboost/releases/tag/v0.32,https://api.github.com/repos/dmlc/xgboost/zipball/v0.32,v0.32,False,False
509889,2014-08-15T20:36:56Z,2014-08-23T02:45:12Z,Latest version of 0.2x,"This is latest version of 0.2x, used to document before changing the code into xgboost-unity
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/509889/assets,https://api.github.com/repos/dmlc/xgboost/releases/509889,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.22,https://github.com/dmlc/xgboost/releases/tag/v0.22,https://api.github.com/repos/dmlc/xgboost/zipball/v0.22,v0.22,False,True
331417,2014-05-20T22:42:19Z,2014-05-20T22:44:48Z,"Second release, with BugFix","Fix a major bug in v0.2   #8  and #10 . 
scale_pos_weight is not properly initialized to default.
The bug will cause binary classification model work improperly when scale_pos_weight is not set in the parameter.

But if the scale_pos_weight is set properly, the result will be correct in v0.2
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/331417/assets,https://api.github.com/repos/dmlc/xgboost/releases/331417,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.21,https://github.com/dmlc/xgboost/releases/tag/v0.21,https://api.github.com/repos/dmlc/xgboost/zipball/v0.21,v0.21,False,False
242694,2014-03-26T23:47:01Z,2014-03-27T00:11:18Z,first release ,"XGBoost with regression and binary classification support
",https://api.github.com/users/tqchen,2577440,tqchen,https://api.github.com/repos/dmlc/xgboost/releases/242694/assets,https://api.github.com/repos/dmlc/xgboost/releases/242694,master,https://api.github.com/repos/dmlc/xgboost/tarball/v0.1,https://github.com/dmlc/xgboost/releases/tag/v0.1,https://api.github.com/repos/dmlc/xgboost/zipball/v0.1,v0.1,False,True
